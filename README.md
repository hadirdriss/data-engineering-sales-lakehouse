# data-engineering-sales-lakehouse

### Project Overview

This project implements a full Data Lakehouse architecture using Databricks, PySpark, and Power BI.
The goal is to build an end-to-end ETL pipeline (Bronze â†’ Silver â†’ Gold) that ingests a CSV file, transforms it, aggregates business metrics, and visualizes results in a Power BI dashboard.

Architecture
![Architecture](data-engineering-sales-lakehouse/diagrams/architecture.jpg)

### ğŸ›  Technologies Used

- **Databricks**

- **PySpark**

- **SQL**

- **Delta Lake**

- **Power BI**

- **Lakehouse Architecture**

- **Data Visualization**

### ğŸ”„ ETL Pipeline


1ï¸âƒ£ Bronze Layer

- **Raw ingestion of CSV**

- **No transformations**

- **Saved as Delta table**

2ï¸âƒ£ Silver Layer

- **Data cleaning (dropna)**

- **Date formatting**

- **Added calculated column total = price * quantity**

3ï¸âƒ£ Gold Layer

- **Aggregation by:**

country

product

order_date

-**Metrics:**

total_sales

total_qty

### Code (Bronze â†’ Silver â†’ Gold)
ğŸ“˜ Bronze â€“ Ingestion

